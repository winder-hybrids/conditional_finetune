# data config
dataset: winder-hybrids/medicaltextbook         # manually download the medical textbook corpus from the MedQA repo https://github.com/jind11/MedQA 
split: train
max_token_length: 2048

# model config
model: meta-llama/Llama-2-7b-hf

# context config
context_type: learned
context: save/context

prompt_tuning:
  num_virtual_tokens: 10
  task_type: 'CAUSAL_LM'

# trainer config
batch_size: 16
accumulate_grad_batches: 1
max_epochs: 5
lr: 3e-5
warmup_ratio: 0.1
lr_scheduler: linear
gradient_clip_val: 1.0

# global config
mode: train
save_dir: save/full_model_learned_context
seed: 1